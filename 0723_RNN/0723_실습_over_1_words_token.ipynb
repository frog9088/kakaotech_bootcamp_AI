{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XQqxMlXmi5EK"
      },
      "outputs": [],
      "source": [
        "# 라이브러리 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn22I9UEi6xV",
        "outputId": "5d228f06-4602-4fee-8486-ab1b81c76279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일이 성공적으로 다운로드되었습니다.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "dataset_file_origin = 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
        "\n",
        "# 요청을 보내고 응답을 받기\n",
        "response = requests.get(dataset_file_origin)\n",
        "\n",
        "# 응답이 성공적이면 파일로 저장\n",
        "if response.status_code == 200:\n",
        "    # 파일을 열고 데이터 쓰기\n",
        "    with open(\"shakespeare.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(response.text)\n",
        "    print(\"파일이 성공적으로 다운로드되었습니다.\")\n",
        "else:\n",
        "    print(f\"파일 다운로드 실패: 상태 코드 {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3ZZMwTzui6zg"
      },
      "outputs": [],
      "source": [
        "text = \"\"\n",
        "with open(\"shakespeare.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JpPvDE5Ai61r"
      },
      "outputs": [],
      "source": [
        "# 데이터 전처리\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(chars)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F-42F89Ji66E"
      },
      "outputs": [],
      "source": [
        "def add_space_before_replace(text, chars):\n",
        "    for char in chars:\n",
        "        text = text.replace(char, f' {char} ')\n",
        "    return text\n",
        "\n",
        "\n",
        "chars_to_replace = ['\\n', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?']\n",
        "\n",
        "processed_text = add_space_before_replace(text, chars_to_replace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j52Nzoldjo7v",
        "outputId": "ef6ef0dd-6492-4a3c-ddf4-654cdbdca526"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen :  \\n Before we proceed any further ,  hear me speak .  \\n  \\n All :  \\n Speak ,  speak . '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "processed_text[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gK2FdG_4job9"
      },
      "outputs": [],
      "source": [
        "words_dict = {}\n",
        "for word in processed_text.lower().split():\n",
        "    if word not in words_dict:\n",
        "        words_dict[word] = 1\n",
        "    else:\n",
        "        words_dict[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "_OszAwQtjgVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c13e04e7-cc27-401f-a820-c707cf92145f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11466"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "#sorted(words_dict.keys())\n",
        "word_dict = sorted(words_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "len(word_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "U3SuKsbAkrZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be589a6b-4a90-4bc3-8efb-3af185f964a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6547"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "word_dict = [word[0] for word in word_dict if word[1] > 1]\n",
        "len(word_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "WrZ0vdVikGFd"
      },
      "outputs": [],
      "source": [
        "words_to_idx = {words: idx for idx, words in enumerate(word_dict)}\n",
        "idx_to_words = {idx: words for idx, words in enumerate(word_dict)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Ux9NZttnkHlO"
      },
      "outputs": [],
      "source": [
        "words_to_idx['UNK'] = len(word_dict)\n",
        "idx_to_words[len(word_dict)] = 'UNK'\n",
        "words_to_idx[' '] = len(word_dict)+1\n",
        "idx_to_words[len(word_dict)+1] = ' '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Wdj9nx_akEAv"
      },
      "outputs": [],
      "source": [
        "# 시퀀스 데이터 생성 함수 정의\n",
        "def create_sequences(text, seq_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(0, len(text) - seq_length):\n",
        "        seq = text[i:i+seq_length]   # 시퀀스 생성\n",
        "        target = text[i+seq_length]  # 시퀀스 다음에 오는 문자\n",
        "        sequences.append([words_to_idx[char] if char in words_to_idx else words_to_idx['UNK'] for char in seq ])\n",
        "        targets.append(words_to_idx[target] if target in words_to_idx else words_to_idx['UNK'])\n",
        "    return sequences, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "4TpwO7DTkP6f"
      },
      "outputs": [],
      "source": [
        "# 시퀀스 길이 설정\n",
        "seq_length = 20\n",
        "\n",
        "# 시퀀스 데이터 생성\n",
        "sequences, targets = create_sequences(text.lower(), seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "XTpswGKrkUt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ff9127-87d7-4d06-a375-c652d9e2875b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6547, 6, 3551, 21, 121, 6548, 4017, 6, 121, 6, 6547, 800, 1576, 1, 6547, 6547, 800, 6547, 52, 3551], [6, 3551, 21, 121, 6548, 4017, 6, 121, 6, 6547, 800, 1576, 1, 6547, 6547, 800, 6547, 52, 3551, 800], [3551, 21, 121, 6548, 4017, 6, 121, 6, 6547, 800, 1576, 1, 6547, 6547, 800, 6547, 52, 3551, 800, 6548], [21, 121, 6548, 4017, 6, 121, 6, 6547, 800, 1576, 1, 6547, 6547, 800, 6547, 52, 3551, 800, 6548, 6547], [121, 6548, 4017, 6, 121, 6, 6547, 800, 1576, 1, 6547, 6547, 800, 6547, 52, 3551, 800, 6548, 6547, 800], [6548, 4017, 6, 121, 6, 6547, 800, 1576, 1, 6547, 6547, 800, 6547, 52, 3551, 800, 6548, 6547, 800, 6548], [4017, 6, 121, 6, 6547, 800, 1576, 1, 6547, 6547, 800, 6547, 52, 3551, 800, 6548, 6547, 800, 6548, 6547], [6, 121, 6, 6547, 800, 1576, 1, 6547, 6547, 800, 6547, 52, 3551, 800, 6548, 6547, 800, 6548, 6547, 3551], [121, 6, 6547, 800, 1576, 1, 6547, 6547, 800, 6547, 52, 3551, 800, 6548, 6547, 800, 6548, 6547, 3551, 52], [6, 6547, 800, 1576, 1, 6547, 6547, 800, 6547, 52, 3551, 800, 6548, 6547, 800, 6548, 6547, 3551, 52, 4017]]\n"
          ]
        }
      ],
      "source": [
        "print(sequences[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "collapsed": true,
        "id": "h7P8XoAYklax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86022b6b-f0ba-4b17-9e58-eb8851f4f28f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "type(idx_to_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "WS2g-WcZmHfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3863c6d-a282-4525-8854-60c00457bbf4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6549"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "len(idx_to_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "BFj35jj6kZTy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2cbcc3dd-6e8f-4c56-aaf4-1b34994b4920"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'patricians'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "idx_to_words[1731]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "hKywsI1Hp_RO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aac83f8-ce7f-4f78-cb26-22a759c15665"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6548"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "words_to_idx[' ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ILgUysz_nnmA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46cedd75-43c6-4a78-bc52-e9d3f6640fc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "sentence = text.lower()\n",
        "result = sentence.split()\n",
        "result_with_spaces = []\n",
        "for word in result:\n",
        "    result_with_spaces.extend([word])\n",
        "    result_with_spaces.append(' ')\n",
        "result_with_spaces.pop() # Remove the last unnecessary space\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "qOq8rYNMpPf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5c30beb2-fbb0-479f-a94a-0b517b70ae57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nsequencess = []\\nfor i in range(0, len(result_with_spaces)):\\n  word = result_with_spaces[i]\\n  print(word)\\n  print(words_to_idx[word])\\n  sequencess.append([words_to_idx[word] if word in words_to_idx else words_to_idx['UNK']])\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "'''\n",
        "sequencess = []\n",
        "for i in range(0, len(result_with_spaces)):\n",
        "  word = result_with_spaces[i]\n",
        "  print(word)\n",
        "  print(words_to_idx[word])\n",
        "  sequencess.append([words_to_idx[word] if word in words_to_idx else words_to_idx['UNK']])\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "EKPGkUS-osXB"
      },
      "outputs": [],
      "source": [
        "sequences, targets = create_sequences(result_with_spaces, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Vu6VucBC3Cm7"
      },
      "outputs": [],
      "source": [
        "# PyTorch 데이터셋 및 데이터로더 생성\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, sequences, targets):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.sequences[idx]), torch.tensor(self.targets[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "hS8QOBVd3CpI"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 및 데이터로더 인스턴스 생성\n",
        "dataset = TextDataset(sequences, targets)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "fmBq4TSH3CrO"
      },
      "outputs": [],
      "source": [
        "# 하이퍼파라미터 설정\n",
        "vocab_size = len(word_dict) + 2\n",
        "hidden_size = 1024\n",
        "output_size = len(word_dict) + 2\n",
        "input_size = 2048\n",
        "num_layers = 2\n",
        "\n",
        "hidden_size_1 = 1024\n",
        "hidden_size_2 = 2048"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Sxa7YIvV7F",
        "outputId": "cc7d68c8-15f9-4009-a1bf-2064fc2239bc"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6549"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "bZTSTxSQ3Cta"
      },
      "outputs": [],
      "source": [
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, input_size, hidden_size_1, hidden_size_2, num_layers=1):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, input_size)  # 임베딩 층\n",
        "        self.hidden_size_1 = hidden_size_1\n",
        "        self.hidden_size_2 = hidden_size_2\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size_1, num_layers, batch_first=True)  # RNN 레이어\n",
        "        self.fc1 = nn.Linear(hidden_size_1, hidden_size_2)\n",
        "        self.fc2 = nn.Linear(hidden_size_2, vocab_size)  # 완전 연결층\n",
        "        self.RelU = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x: (batch_size, seq_length)\n",
        "        x = self.embeddings(x)  # 임베딩 층 통과 -> (batch_size, seq_length, input_size)\n",
        "        out, hidden = self.rnn(x, hidden)  # RNN 순전파\n",
        "        x = self.fc1(out[:, -1, :])\n",
        "        x = self.RelU(x)\n",
        "        out = self.fc2(x)\n",
        "        # 마지막 시퀀스 출력만 사용 -> (batch_size, output_size)\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # 초기 hidden state 설정\n",
        "        return torch.zeros(self.num_layers, batch_size, self.hidden_size_1).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "YBh9bFvF3Cvr"
      },
      "outputs": [],
      "source": [
        "# GPU 사용 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 모델 인스턴스 생성 및 GPU로 이동\n",
        "model = RNNModel(vocab_size, hidden_size, output_size, num_layers).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "H4A9MeCD3Czg"
      },
      "outputs": [],
      "source": [
        "# 손실 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "B2V1_zWo3C5t"
      },
      "outputs": [],
      "source": [
        "# 모델 훈련 함수\n",
        "def train_model(model, dataloader, criterion, optimizer, num_epochs=20):\n",
        "    model.train()  # 모델을 훈련 모드로 설정\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in dataloader:\n",
        "            #inputs = nn.functional.one_hot(inputs, num_classes=vocab_size).float() # 원-핫 인코딩 및 GPU로 이동\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            hidden = model.init_hidden(inputs.size(0))  # 각 배치마다 hidden 상태 초기화\n",
        "\n",
        "            # 옵티마이저 초기화\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 순전파, 역전파, 최적화\n",
        "            outputs, hidden = model(inputs, hidden)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # hidden 상태를 detach하여 그래프의 연결을 끊음\n",
        "            hidden = hidden.detach()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(dataloader):.4f}')\n",
        "\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "cbYiyld_3Kz5"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_str, length, temperature=1.0):\n",
        "    model.eval()  # 모델을 평가 모드로 설정\n",
        "    hidden = model.init_hidden(1)  # 초기 hidden 상태 설정\n",
        "\n",
        "    input_seq = torch.tensor([words_to_idx[char] if char in words_to_idx else words_to_idx['UNK'] for char in start_str]).unsqueeze(0).to(device)\n",
        "    generated_text = start_str\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(length):\n",
        "            #input_seq = nn.functional.one_hot(input_seq, num_classes=vocab_size).float()\n",
        "            output, hidden = model(input_seq, hidden)\n",
        "\n",
        "            # 다음 문자를 샘플링\n",
        "            output = output.squeeze().div(temperature).exp().cpu()\n",
        "            top_char = torch.multinomial(output, 1)[0]\n",
        "            generated_char = idx_to_words[top_char.item()]\n",
        "            generated_text += generated_char\n",
        "\n",
        "            # 다음 입력 시퀀스 준비\n",
        "            input_seq = torch.tensor([[top_char]]).to(device)\n",
        "\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "xt1djGK43K2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e905dc4-8267-4a85-b02b-f00df154a291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 5.4141\n",
            "Epoch 2/3, Loss: 3.2415\n",
            "Epoch 3/3, Loss: 3.1897\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# 모델 훈련\n",
        "train_model(model, dataloader, criterion, optimizer, num_epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "2rjSGXkx3K4Y"
      },
      "outputs": [],
      "source": [
        "# 테스트 시작 문자열 및 생성할 텍스트 길이\n",
        "start_str = \"To be, or not to be, that is the question:\".lower()\n",
        "length = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_words[6548]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7cfSJ5KPALP9",
        "outputId": "f3f8c143-abc9-413c-f657-5d46811641a8"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 생성\n",
        "generated_text = generate_text(model, start_str, length, temperature=0.8)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCr_o0r0_6MC",
        "outputId": "f7e8f053-ae96-450d-d54e-64d69a066ff9"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to be, or not to be, that is the question:        UNK UNK     UNKand               UNK   UNKUNKloveUNK       UNK        UNK    UNK you UNK       UNK      of UNK their UNK  UNK UNK   UNKmust UNK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0P1mpJjY_6O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5q7yG32u3K6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e1dfb3-f5a5-4ba5-b1cc-933449d35967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be, or not to be, that is the question:a again are UNK UNK simple UNK UNK UNK UNK UNK UNK alack you UNK that he UNK alack UNK UNK cannot UNK UNK UNK UNK he UNK look and i and he he fortune UNK UNK been UNK had UNK been alack UNK some the UNK the UNK again \n"
          ]
        }
      ],
      "source": [
        "# 텍스트 생성\n",
        "generated_text = generate_text(model, start_str, length, temperature=0.8)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Pn5lg0y33C71"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}