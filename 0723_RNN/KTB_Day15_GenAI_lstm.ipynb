{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WAjmgY7til__"
      },
      "outputs": [],
      "source": [
        "# 라이브러리 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "dataset_file_origin = 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
        "\n",
        "# 요청을 보내고 응답을 받기\n",
        "response = requests.get(dataset_file_origin)\n",
        "\n",
        "# 응답이 성공적이면 파일로 저장\n",
        "if response.status_code == 200:\n",
        "    # 파일을 열고 데이터 쓰기\n",
        "    with open(\"shakespeare.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(response.text)\n",
        "    print(\"파일이 성공적으로 다운로드되었습니다.\")\n",
        "else:\n",
        "    print(f\"파일 다운로드 실패: 상태 코드 {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-5zzkAUioqv",
        "outputId": "29d1a5a1-0551-4924-dad4-319f2a903433"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일이 성공적으로 다운로드되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\n",
        "with open(\"shakespeare.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text = file.read()\n",
        "print(text[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UidMJ_cviqaQ",
        "outputId": "e0cfc162-f225-4867-e25f-88471c8dab1d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCp4Jy0HKiia",
        "outputId": "62e9a234-1edf-4a77-9640-b39594743032"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(chars)}"
      ],
      "metadata": {
        "id": "bD6MkpmSiuvM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시퀀스 데이터 생성 함수 정의\n",
        "def create_sequences(text, seq_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(0, len(text) - seq_length):\n",
        "        seq = text[i:i+seq_length]   # 시퀀스 생성\n",
        "        target = text[i+seq_length]  # 시퀀스 다음에 오는 문자\n",
        "        sequences.append([char_to_idx[char] for char in seq])\n",
        "        targets.append(char_to_idx[target])\n",
        "    return sequences, targets"
      ],
      "metadata": {
        "id": "r2XYQVC3ius7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시퀀스 길이 설정\n",
        "seq_length = 100\n",
        "\n",
        "# 시퀀스 데이터 생성\n",
        "sequences, targets = create_sequences(text, seq_length)"
      ],
      "metadata": {
        "id": "O8dE8rzEiuqR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIotsE3hiunf",
        "outputId": "f1e364c6-4850-4635-a882-7194d2ae532d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59], [47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1], [56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39], [57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56], [58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56, 43], [1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56, 43, 1], [15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56, 43, 1, 39], [47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56, 43, 1, 39, 50], [58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56, 43, 1, 39, 50, 50], [47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56, 43, 1, 39, 50, 50, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch 데이터셋 및 데이터로더 생성\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, sequences, targets):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.sequences[idx]), torch.tensor(self.targets[idx])"
      ],
      "metadata": {
        "id": "Je-ts_XQi136"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 및 데이터로더 인스턴스 생성\n",
        "dataset = TextDataset(sequences, targets)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "9M9qZrSLi105"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "vocab_size = len(chars)\n",
        "hidden_size = 256\n",
        "output_size = len(chars)\n",
        "num_layers = 2"
      ],
      "metadata": {
        "id": "wmVF35_ai1yG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, output_size, num_layers=1):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(vocab_size, hidden_size, num_layers, batch_first=True)  # LSTM 레이어\n",
        "        self.fc = nn.Linear(hidden_size, output_size)  # 완전 연결층\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        out, hidden = self.lstm(x, hidden)  # LSTM 순전파\n",
        "        out = self.fc(out[:, -1, :])  # 마지막 시퀀스 출력만 사용\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # 초기 hidden state 설정\n",
        "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device),\n",
        "                torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device))\n"
      ],
      "metadata": {
        "id": "S0BZwfZ_i1vo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 사용 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 모델 인스턴스 생성 및 GPU로 이동\n",
        "model = LSTMModel(vocab_size, hidden_size, output_size, num_layers).to(device)"
      ],
      "metadata": {
        "id": "7PpI-aUCi1tA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "K7kilk_-i1ld"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련 함수\n",
        "def train_model(model, dataloader, criterion, optimizer, num_epochs=20):\n",
        "    model.train()  # 모델을 훈련 모드로 설정\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = nn.functional.one_hot(inputs, num_classes=vocab_size).float().to(device)  # 원-핫 인코딩 및 GPU로 이동\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            hidden = model.init_hidden(inputs.size(0))  # 각 배치마다 hidden 상태 초기화\n",
        "\n",
        "            # 옵티마이저 초기화\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 순전파, 역전파, 최적화\n",
        "            outputs, hidden = model(inputs, hidden)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # hidden 상태를 detach하여 그래프의 연결을 끊음\n",
        "            hidden = (hidden[0].detach(), hidden[1].detach())\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(dataloader):.4f}')\n",
        "\n",
        "    print('Finished Training')"
      ],
      "metadata": {
        "id": "qu7GlmAOi_Z3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_str, length, temperature=1.0):\n",
        "    model.eval()  # 모델을 평가 모드로 설정\n",
        "    hidden = model.init_hidden(1)  # 초기 hidden 상태 설정\n",
        "\n",
        "    input_seq = torch.tensor([char_to_idx[char] for char in start_str]).unsqueeze(0).to(device)\n",
        "    generated_text = start_str\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(length):\n",
        "            input_seq = nn.functional.one_hot(input_seq, num_classes=vocab_size).float()\n",
        "            output, hidden = model(input_seq, hidden)\n",
        "\n",
        "            # 다음 문자를 샘플링\n",
        "            output = output.squeeze().div(temperature).exp().cpu()\n",
        "            top_char = torch.multinomial(output, 1)[0]\n",
        "\n",
        "            generated_char = idx_to_char[top_char.item()]\n",
        "            generated_text += generated_char\n",
        "\n",
        "            # 다음 입력 시퀀스 준비\n",
        "            input_seq = torch.tensor([[top_char]]).to(device)\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "jjBu8_U_jKMj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTVcccLXj76J",
        "outputId": "9b1cf4d0-1543-4a46-ee1f-8f4100973571"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMModel(\n",
            "  (lstm): LSTM(65, 256, num_layers=2, batch_first=True)\n",
            "  (fc): Linear(in_features=256, out_features=65, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "train_model(model, dataloader, criterion, optimizer, num_epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr0Pdpl6i_XQ",
        "outputId": "7b58ded2-f8bb-4c91-d62b-a27043b031e9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 1.7038\n",
            "Epoch 2/5, Loss: 1.3778\n",
            "Epoch 3/5, Loss: 1.3028\n",
            "Epoch 4/5, Loss: 1.2580\n",
            "Epoch 5/5, Loss: 1.2250\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 시작 문자열 및 생성할 텍스트 길이\n",
        "start_str = \"To be, or not to be, that is the question:\"\n",
        "length = 200"
      ],
      "metadata": {
        "id": "LA-v_4uOi_UV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 생성\n",
        "generated_text = generate_text(model, start_str, length, temperature=0.8)\n",
        "print(generated_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INlzk51JjNIQ",
        "outputId": "be8f645b-2dcd-4209-b4e2-91545fa0d8c3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be, or not to be, that is the question:\n",
            "Which I will give myself for you,\n",
            "You make him here, if nothing lie in exile:\n",
            "I will, sir.\n",
            "\n",
            "GREMIO:\n",
            "Nay, is your aim.\n",
            "\n",
            "PETRUCHIO:\n",
            "It may not, sir:\n",
            "They are sweetest while they are all mine honour:\n",
            "Th\n"
          ]
        }
      ]
    }
  ]
}