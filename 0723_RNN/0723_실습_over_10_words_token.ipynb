{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "WAjmgY7til__"
      },
      "outputs": [],
      "source": [
        "# 라이브러리 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "dataset_file_origin = 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
        "\n",
        "# 요청을 보내고 응답을 받기\n",
        "response = requests.get(dataset_file_origin)\n",
        "\n",
        "# 응답이 성공적이면 파일로 저장\n",
        "if response.status_code == 200:\n",
        "    # 파일을 열고 데이터 쓰기\n",
        "    with open(\"shakespeare.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(response.text)\n",
        "    print(\"파일이 성공적으로 다운로드되었습니다.\")\n",
        "else:\n",
        "    print(f\"파일 다운로드 실패: 상태 코드 {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-5zzkAUioqv",
        "outputId": "346a885a-0460-4b07-f3e9-bb5d45614f77"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일이 성공적으로 다운로드되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\n",
        "with open(\"shakespeare.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text = file.read()\n",
        "print(text[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UidMJ_cviqaQ",
        "outputId": "f8ccebb3-9846-47f4-a7a1-f08438f4c8db"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "chars = sorted(list(set(text)))"
      ],
      "metadata": {
        "id": "bD6MkpmSiuvM"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z3qgIYFqxSJ",
        "outputId": "44aa9c04-b53c-4dc9-953d-c990b2fa8e72"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_space_before_replace(text, chars):\n",
        "    for char in chars:\n",
        "        text = text.replace(char, f' {char} ')\n",
        "    return text\n",
        "\n",
        "\n",
        "chars_to_replace = ['\\n', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?']\n",
        "\n",
        "processed_text = add_space_before_replace(text, chars_to_replace)"
      ],
      "metadata": {
        "id": "k8VgHrwQqDCH"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sorted(words_dict.keys())\n",
        "word_dict = sorted(words_dict.items(), key=lambda x: x[1], reverse=True)\n"
      ],
      "metadata": {
        "id": "ijqT9PfSkB-z"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(words_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE_Cy8Nboq_R",
        "outputId": "bba76cfa-6b49-4898-bc61-9fcdaa07c6b4"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = sorted(list(set(processed_text.lower().split())))"
      ],
      "metadata": {
        "id": "K-0xhnsNqpc-"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_list = set(processed_text.lower().split())"
      ],
      "metadata": {
        "id": "rAjgrdWSjUnk"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [word for word in words if len(word) > 1]"
      ],
      "metadata": {
        "id": "UdaFsvIyr45-"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ns_dZt74qr7o",
        "outputId": "2058344b-2916-4fd3-9ba3-50c59f2ee302"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abandon',\n",
              " 'abase',\n",
              " 'abate',\n",
              " 'abated',\n",
              " 'abbey',\n",
              " 'abbot',\n",
              " 'abed',\n",
              " 'abel',\n",
              " 'abet',\n",
              " 'abhor',\n",
              " 'abhorr',\n",
              " 'abhorred',\n",
              " 'abhorring',\n",
              " 'abhors',\n",
              " 'abhorson',\n",
              " 'abide',\n",
              " 'abides',\n",
              " 'abilities',\n",
              " 'ability',\n",
              " 'abject',\n",
              " 'abjects',\n",
              " 'abjured',\n",
              " 'able',\n",
              " 'aboard',\n",
              " 'abode',\n",
              " 'abodements',\n",
              " 'aboding',\n",
              " 'abominable',\n",
              " 'abortive',\n",
              " 'abound',\n",
              " 'about',\n",
              " 'above',\n",
              " 'abraham',\n",
              " 'abreast',\n",
              " 'abroach',\n",
              " 'abroad',\n",
              " 'absence',\n",
              " 'absent',\n",
              " 'absolute',\n",
              " 'absolutely',\n",
              " 'absolved',\n",
              " 'absolver',\n",
              " 'abstains',\n",
              " 'abstinence',\n",
              " 'abstract',\n",
              " 'abundance',\n",
              " 'abundant',\n",
              " 'abundantly',\n",
              " 'abuse',\n",
              " 'abused',\n",
              " 'abuses',\n",
              " 'abusing',\n",
              " 'abysm',\n",
              " 'accent',\n",
              " 'accents',\n",
              " 'accept',\n",
              " 'acceptance',\n",
              " 'access',\n",
              " 'accessary',\n",
              " 'accident',\n",
              " 'accidental',\n",
              " 'accidentally',\n",
              " 'accidents',\n",
              " 'acclamations',\n",
              " 'accommodations',\n",
              " 'accompanied',\n",
              " 'accompany',\n",
              " 'accomplish',\n",
              " 'accomplished',\n",
              " 'accompt',\n",
              " 'accord',\n",
              " 'according',\n",
              " 'accordingly',\n",
              " 'accords',\n",
              " 'account',\n",
              " 'accountant',\n",
              " 'accounted',\n",
              " 'accoutrements',\n",
              " 'accursed',\n",
              " 'accurst',\n",
              " 'accusation',\n",
              " 'accusations',\n",
              " 'accuse',\n",
              " 'accused',\n",
              " 'accuser',\n",
              " 'accusers',\n",
              " 'accuses',\n",
              " 'accuseth',\n",
              " 'accustom',\n",
              " 'ache',\n",
              " 'aches',\n",
              " 'achieve',\n",
              " 'achieved',\n",
              " 'achieving',\n",
              " 'aching',\n",
              " 'acknowledge',\n",
              " 'acknowledged',\n",
              " 'acorn',\n",
              " 'acquaint',\n",
              " 'acquaintance']"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_dict = {}\n",
        "for word in processed_text.lower().split():\n",
        "    if word not in words_dict:\n",
        "        words_dict[word] = 1\n",
        "    else:\n",
        "        words_dict[word] += 1"
      ],
      "metadata": {
        "id": "EKHzCFf8j86J"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_dict = [word[0] for word in word_dict if word[1] > 10]\n",
        "len(word_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUNBy__WqkYD",
        "outputId": "ff44ae29-42ed-4333-d6e3-1857805d4670"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1731"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_to_idx = {words: idx for idx, words in enumerate(word_dict)}\n",
        "idx_to_words = {idx: words for idx, words in enumerate(word_dict)}"
      ],
      "metadata": {
        "id": "XjSiW8xXpT6M"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_to_idx['UNK'] = len(word_dict)\n",
        "idx_to_words[len(word_dict)] = 'UNK'"
      ],
      "metadata": {
        "id": "rJHH12W-rarG"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시퀀스 데이터 생성 함수 정의\n",
        "def create_sequences(text, seq_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(0, len(text) - seq_length):\n",
        "        seq = text[i:i+seq_length]   # 시퀀스 생성\n",
        "        target = text[i+seq_length]  # 시퀀스 다음에 오는 문자\n",
        "        sequences.append([words_to_idx[char] if char in words_to_idx else words_to_idx['UNK'] for char in seq ])\n",
        "        targets.append(words_to_idx[target] if target in words_to_idx else words_to_idx['UNK'])\n",
        "    return sequences, targets"
      ],
      "metadata": {
        "id": "r2XYQVC3ius7"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시퀀스 길이 설정\n",
        "seq_length = 20\n",
        "\n",
        "# 시퀀스 데이터 생성\n",
        "sequences, targets = create_sequences(processed_text.lower().split(), seq_length)"
      ],
      "metadata": {
        "id": "O8dE8rzEiuqR"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIotsE3hiunf",
        "outputId": "50a3ba9e-b8d2-4054-c282-624280bd04c2"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[100, 283, 1, 152, 40, 985, 158, 678, 0, 137, 24, 114, 2, 43, 1, 114, 0, 114, 2, 100], [283, 1, 152, 40, 985, 158, 678, 0, 137, 24, 114, 2, 43, 1, 114, 0, 114, 2, 100, 283], [1, 152, 40, 985, 158, 678, 0, 137, 24, 114, 2, 43, 1, 114, 0, 114, 2, 100, 283, 1], [152, 40, 985, 158, 678, 0, 137, 24, 114, 2, 43, 1, 114, 0, 114, 2, 100, 283, 1, 10], [40, 985, 158, 678, 0, 137, 24, 114, 2, 43, 1, 114, 0, 114, 2, 100, 283, 1, 10, 50], [985, 158, 678, 0, 137, 24, 114, 2, 43, 1, 114, 0, 114, 2, 100, 283, 1, 10, 50, 43], [158, 678, 0, 137, 24, 114, 2, 43, 1, 114, 0, 114, 2, 100, 283, 1, 10, 50, 43, 1274], [678, 0, 137, 24, 114, 2, 43, 1, 114, 0, 114, 2, 100, 283, 1, 10, 50, 43, 1274, 363], [0, 137, 24, 114, 2, 43, 1, 114, 0, 114, 2, 100, 283, 1, 10, 50, 43, 1274, 363, 7], [137, 24, 114, 2, 43, 1, 114, 0, 114, 2, 100, 283, 1, 10, 50, 43, 1274, 363, 7, 213]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch 데이터셋 및 데이터로더 생성\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, sequences, targets):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.sequences[idx]), torch.tensor(self.targets[idx])"
      ],
      "metadata": {
        "id": "Je-ts_XQi136"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 및 데이터로더 인스턴스 생성\n",
        "dataset = TextDataset(sequences, targets)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "9M9qZrSLi105"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "vocab_size = len(word_dict) + 1\n",
        "hidden_size = 256\n",
        "output_size = len(word_dict) + 1\n",
        "input_size = 2048\n",
        "num_layers = 2"
      ],
      "metadata": {
        "id": "wmVF35_ai1yG"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, input_size, hidden_size, num_layers=1):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, input_size)  # 임베딩 층\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)  # RNN 레이어\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)  # 완전 연결층\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x: (batch_size, seq_length)\n",
        "        x = self.embeddings(x)  # 임베딩 층 통과 -> (batch_size, seq_length, input_size)\n",
        "        out, hidden = self.rnn(x, hidden)  # RNN 순전파\n",
        "        out = self.fc(out[:, -1, :])  # 마지막 시퀀스 출력만 사용 -> (batch_size, output_size)\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # 초기 hidden state 설정\n",
        "        return torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n"
      ],
      "metadata": {
        "id": "WF_Gw4J1sRQb"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 사용 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 모델 인스턴스 생성 및 GPU로 이동\n",
        "model = RNNModel(vocab_size, hidden_size, output_size, num_layers).to(device)"
      ],
      "metadata": {
        "id": "fh2lnbbHsRTR"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "6gSksAylsRV2"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련 함수\n",
        "def train_model(model, dataloader, criterion, optimizer, num_epochs=20):\n",
        "    model.train()  # 모델을 훈련 모드로 설정\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in dataloader:\n",
        "            #inputs = nn.functional.one_hot(inputs, num_classes=vocab_size).float() # 원-핫 인코딩 및 GPU로 이동\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            hidden = model.init_hidden(inputs.size(0))  # 각 배치마다 hidden 상태 초기화\n",
        "\n",
        "            # 옵티마이저 초기화\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 순전파, 역전파, 최적화\n",
        "            outputs, hidden = model(inputs, hidden)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # hidden 상태를 detach하여 그래프의 연결을 끊음\n",
        "            hidden = hidden.detach()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(dataloader):.4f}')\n",
        "\n",
        "    print('Finished Training')"
      ],
      "metadata": {
        "id": "MKAr9HewsRYH"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_str, length, temperature=1.0):\n",
        "    model.eval()  # 모델을 평가 모드로 설정\n",
        "    hidden = model.init_hidden(1)  # 초기 hidden 상태 설정\n",
        "\n",
        "    input_seq = torch.tensor([words_to_idx[char] if char in words_to_idx else words_to_idx['UNK'] for char in start_str]).unsqueeze(0).to(device)\n",
        "    generated_text = start_str\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(length):\n",
        "            #input_seq = nn.functional.one_hot(input_seq, num_classes=vocab_size).float()\n",
        "            output, hidden = model(input_seq, hidden)\n",
        "\n",
        "            # 다음 문자를 샘플링\n",
        "            output = output.squeeze().div(temperature).exp().cpu()\n",
        "            top_char = torch.multinomial(output, 1)[0]\n",
        "\n",
        "            generated_char = idx_to_words[top_char.item()]\n",
        "            generated_text += generated_char\n",
        "\n",
        "            # 다음 입력 시퀀스 준비\n",
        "            input_seq = torch.tensor([[top_char]]).to(device)\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "oiWsag3FsRac"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "train_model(model, dataloader, criterion, optimizer, num_epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6WXZqv4sRcu",
        "outputId": "6838d556-e0e6-42b1-d8fb-d69fdb8072ff"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 7.1866\n",
            "Epoch 2/5, Loss: 6.8305\n",
            "Epoch 3/5, Loss: 6.5715\n",
            "Epoch 4/5, Loss: 6.5109\n",
            "Epoch 5/5, Loss: 6.5289\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 시작 문자열 및 생성할 텍스트 길이\n",
        "start_str = \"To be, or not to be, that is the question:\"\n",
        "length = 100"
      ],
      "metadata": {
        "id": "Vq8eoTxLsbOE"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 생성\n",
        "generated_text = generate_text(model, start_str, length, temperature=0.8)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "07nouC8AsbQX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b817488-06ac-4dc9-b4fb-c80cda924356"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be, or not to be, that is the question:usanywithqueenhe,the?firepoorlady?daysetmenwithlikeme,left??,UNK,himwrongallyouveryUNKatis,withi,UNKand?UNKlikemustfriarthouandi',,?must:twotoUNKUNK,fatherbeUNKsetisetlady.thusillandthevalour,inyou?theangeloenterstands,thouUNK,queen,ofttrickbanishshallat:,aatoenterlikehimthe\n"
          ]
        }
      ]
    }
  ]
}
