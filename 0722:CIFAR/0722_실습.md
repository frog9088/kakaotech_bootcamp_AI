


##  데이터셋



### 데이터셋 개요





**CIFAR-100**은 50,000개의 train 이미지와 10,000개의 test 이미지로 구성되어 있습니다.



모든 이미지는 32x32 크기의 3채널 color 이미지로 주어지며 이를 100개의 class로 분류해야 합니다.




> 데이터셋 전처리
```python
from torchvision import datasets, transforms

transform = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])
```

> 데이터셋 다운로드
```python
from pathlib import Path
from torchvision import datasets
import torch

DATA_ROOT = Path("./data") # modify this
trainset = datasets.CIFAR100(DATA_ROOT, train=True, download=True, transform=transform)
testset = datasets.CIFAR100(DATA_ROOT, train=False, download=True, transform=transform)
```

<pre>
Files already downloaded and verified
Files already downloaded and verified
</pre>

```python
train_loader = torch.utils.data.DataLoader(trainset, batch_size=4096, shuffle=True, num_workers=2, pin_memory=True)
test_loader = torch.utils.data.DataLoader(testset, batch_size=4096, shuffle=True, num_workers=2, pin_memory=True)
```



## 분류모델 학습과 평가



### My own model 



> 모델 1
```python
from torch import nn, Tensor, optim

class Your_Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(128)
        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(256)
        self.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)
        self.bn4 = nn.BatchNorm2d(512)

        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.dropout = nn.Dropout(p=0.4)

        self.fc1 = nn.Linear(in_features=512*2*2, out_features=1024)
        self.fc2 = nn.Linear(in_features=1024, out_features=512)
        self.fc3 = nn.Linear(in_features=512, out_features=100)
    def forward(self, x:Tensor):
        x = self.pool(nn.functional.relu(self.bn1(self.conv1(x))))
        x = self.pool(nn.functional.relu(self.bn2(self.conv2(x))))
        x = self.pool(nn.functional.relu(self.bn3(self.conv3(x))))
        x = self.pool(nn.functional.relu(self.bn4(self.conv4(x))))

        x = x.view(-1, 512*2*2)

        x = nn.functional.relu(self.fc1(x))
        x = self.dropout(x)
        x = nn.functional.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)

        return x

```


> Training





```python
# 모델과 손실 함수, 옵티마이저 정의
device = torch.device("cuda")
model = Your_Model2().to(device)  # 모델을 GPU로 이동
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 학습 설정
num_epochs = 100

```


```python
for epoch in range(num_epochs):  # 에포크 반복
    model.train()
    running_loss = 0.0

    for inputs, labels in train_loader:
        # 데이터와 레이블을 디바이스로 이동
        inputs, labels = inputs.cuda(), labels.cuda()

        # 옵티마이저 초기화
        optimizer.zero_grad()

        # 순전파
        outputs = model(inputs)
        loss = criterion(outputs, labels)

        # 역전파 및 옵티마이저 스텝
        loss.backward()
        optimizer.step()

        # 손실 누적
        running_loss += loss.item()

    # 에포크마다 평균 손실 출력
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}")
```


```python
def calculate_accuracy(outputs, labels):
    _, predicted = torch.max(outputs, 1)
    correct = (predicted == labels).sum().item()
    total = labels.size(0)
    accuracy = correct / total
    return accuracy
```


```python

import matplotlib.pyplot as plt

def train_model(model, criterion, optimizer, train_loader, num_epochs):
    train_losses = []
    train_accuracies = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.cuda(), labels.cuda()
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        epoch_loss = running_loss / len(train_loader)
        epoch_accuracy = correct / total

        train_losses.append(epoch_loss)
        train_accuracies.append(epoch_accuracy)

        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

    return train_losses, train_accuracies

# Assuming train_loader is defined elsewhere
train_losses, train_accuracies = train_model(model, criterion, optimizer, train_loader, num_epochs)
```

<pre>
Epoch [1/100], Loss: 4.3294, Accuracy: 0.0546
Epoch [10/100], Loss: 2.8620, Accuracy: 0.2835
Epoch [20/100], Loss: 2.4787, Accuracy: 0.3610
Epoch [30/100], Loss: 2.3017, Accuracy: 0.3968
Epoch [40/100], Loss: 2.1767, Accuracy: 0.4237
Epoch [50/100], Loss: 2.0785, Accuracy: 0.4451
Epoch [60/100], Loss: 2.0193, Accuracy: 0.4571
Epoch [70/100], Loss: 1.9491, Accuracy: 0.4744
Epoch [80/100], Loss: 1.8962, Accuracy: 0.4860
Epoch [90/100], Loss: 1.8626, Accuracy: 0.4962
Epoch [100/100], Loss: 1.8029, Accuracy: 0.5046
</pre>



> 시각화
```python
plt.figure(figsize=(10, 5))

# Plotting Loss
plt.subplot(1, 2, 1)
plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training Loss over epochs')
plt.legend()

# Plotting Accuracy
plt.subplot(1, 2, 2)
plt.plot(range(1, num_epochs+1), train_accuracies, label='Training Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training Accuracy over epochs')
plt.legend()

plt.tight_layout()
plt.show()
```
![시각화](./img/시각화.png)

> Evaluation 
##### CIFAR-100의 `test` dataset으로 정확도를 평가



```python
model.eval()
correct = 0
total = 0

with torch.no_grad():
    for inputs, labels in test_loader:

        inputs, labels = inputs.cuda(), labels.cuda()
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

accuracy = 100 * correct / total
print(f'Accuracy of the model on the', total, f'test images: {accuracy:.2f}%')
```

<pre>
Accuracy of the model on the 10000 test images: 48.68%
</pre>
> 모델 2
```python
from torch import nn, Tensor, optim

class Your_Model2(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)

        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.dropout = nn.Dropout(p=0.4)

        self.fc1 = nn.Linear(in_features=64*8*8, out_features=1024)
        self.fc2 = nn.Linear(in_features=1024, out_features=100)

    def forward(self, x:Tensor):
        x = self.pool(nn.functional.relu(self.bn1(self.conv1(x))))
        x = self.pool(nn.functional.relu(self.bn2(self.conv2(x))))

        x = x.view(-1, 64*8*8)

        x = nn.functional.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)

        return x

```


> Training
```python
torch.cuda.empty_cache()
# 모델과 손실 함수, 옵티마이저 정의
device = torch.device("cuda")
model = Your_Model().to(device)  # 모델을 GPU로 이동
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 학습 설정
num_epochs = 100

train_losses, train_accuracies = train_model(model, criterion, optimizer, train_loader, num_epochs)
```

<pre>
Epoch [1/100], Loss: 4.3454, Accuracy: 0.0398
Epoch [10/100], Loss: 2.6615, Accuracy: 0.3080
Epoch [20/100], Loss: 2.0726, Accuracy: 0.4339
Epoch [30/100], Loss: 1.7516, Accuracy: 0.5092
Epoch [40/100], Loss: 1.5407, Accuracy: 0.5612
Epoch [50/100], Loss: 1.3817, Accuracy: 0.6010
Epoch [60/100], Loss: 1.2450, Accuracy: 0.6345
Epoch [70/100], Loss: 1.1558, Accuracy: 0.6554
Epoch [80/100], Loss: 1.0479, Accuracy: 0.6822
Epoch [90/100], Loss: 0.9825, Accuracy: 0.7018
Epoch [100/100], Loss: 0.9068, Accuracy: 0.7195
</pre>



> Evaluation 
```python
model.eval()
correct = 0
total = 0

with torch.no_grad():
    for inputs, labels in test_loader:

        inputs, labels = inputs.cuda(), labels.cuda()
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

accuracy = 100 * correct / total
print(f'Accuracy of the model on the', total, f'test images: {accuracy:.2f}%')
```

<pre>
Accuracy of the model on the 10000 test images: 58.53%
</pre>
